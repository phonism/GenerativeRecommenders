import generative_recommenders.data.p5_amazon

train.epochs=5000
train.learning_rate=3e-4
train.num_warmup_steps=100
train.weight_decay=0.035
train.batch_size=256
train.embedding_dim=128
train.attn_dim=512
train.dropout=0.3
train.num_heads=8
train.n_layers=8
train.num_item_embeddings=256
train.num_user_embeddings=2000
train.sem_id_dim=3
train.gradient_accumulate_every=1
train.save_model_every=3000000
train.eval_every=10000
train.max_seq_len=512
train.pretrained_rqvae_path="./out/rqvae/p5_amazon/beauty/checkpoint_299999.pt"
train.dataset_folder="dataset/amazon"
train.dataset=@P5AmazonReviewsSeqDataset
train.save_dir_root="out/tiger/p5_amazon/beauty/"
train.wandb_logging=True
train.wandb_project="p5_amazon_beauty_tiger_training"
train.wandb_log_interval=1
train.do_eval=True